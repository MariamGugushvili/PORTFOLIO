# -*- coding: utf-8 -*-
"""+++CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hAT4bwrEYMTr2i2iUHLZZCh_ipoCLQib

CNN
"""

import tensorflow as tf
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.utils import plot_model
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns
import numpy as np
from sklearn.metrics import classification_report

(x_train, y_train), (x_test, y_test) = cifar10.load_data()

x_train, x_test = x_train / 255.0, x_test / 255.0

INPUT_SHAPE = (32, 32, 3)
KERNEL_SIZE = (3, 3)

model = Sequential([
    # Convolutional Layers
    Conv2D(32, KERNEL_SIZE, activation='relu', padding='same', input_shape=INPUT_SHAPE),
    BatchNormalization(),
    Conv2D(32, KERNEL_SIZE, activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.25),
    Conv2D(64, KERNEL_SIZE, activation='relu', padding='same'),
    BatchNormalization(),
    Conv2D(64, KERNEL_SIZE, activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.25),
    Conv2D(128, KERNEL_SIZE, activation='relu', padding='same'),
    BatchNormalization(),
    Conv2D(128, KERNEL_SIZE, activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.25),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.25),
    Dense(10, activation='softmax')
])

total_params = model.count_params()
print(f"Total parameters: {total_params}")

import tensorflow as tf

# Assuming you have a model 'model'
for layer in model.layers:
    if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.Dense):
        weights, biases = layer.get_weights()
        print(f"Layer: {layer.name}")
        print(f"Weights shape: {weights.shape}")
        print(f"Biases shape: {biases.shape}")

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test))

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Loss Function Evaluation')
plt.legend()

plt.show()

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Accuracy Function Evaluation')
plt.legend()

plt.show()

# Make predictions on the test set
y_pred = model.predict(x_test)
y_pred_classes = np.argmax(y_pred, axis=1)

# Compute the confusion matrix
cm = confusion_matrix(y_test, y_pred_classes)

# Visualize the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Make predictions on the test set
y_pred = model.predict(x_test)
# Convert predictions to class labels
y_pred_classes = np.argmax(y_pred, axis=1)
# Use the predicted classes instead of raw predictions
print(classification_report(y_test, y_pred_classes)) # Changed y_pred to y_pred_classes