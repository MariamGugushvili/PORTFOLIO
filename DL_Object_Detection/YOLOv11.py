# -*- coding: utf-8 -*-
"""

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15RV1bPdLwA93xSFRf22OkvtZBcIX4iiP

TEST
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import zipfile
import random
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from shutil import copyfile

!mkdir tmp

local_zip_image = '/content/drive/MyDrive/Colab Notebooks/image-20210112T150225Z-001.zip'
local_zip_label = '/content/drive/MyDrive/Colab Notebooks/label-20210112T150240Z-001-2.zip'
zip_ref_image   = zipfile.ZipFile(local_zip_image, 'r')
zip_ref_label   = zipfile.ZipFile(local_zip_label, 'r')
zip_ref_image.extractall('/content/tmp')
zip_ref_image.close()

zip_ref_label.extractall('/content/tmp')
zip_ref_image.close()

print(len(os.listdir('/content/tmp/image')))
print(len(os.listdir('/content/tmp/label')))

import os
import shutil
import random

def split_dataset(source_dir, target_dir, split_ratios):
    # Get a list of all image filenames
    image_filenames = os.listdir(os.path.join(source_dir, 'image'))

    # Shuffle the filenames randomly
    random.shuffle(image_filenames)

    # Calculate the number of images for each set
    num_train = int(len(image_filenames) * split_ratios[0])
    num_val = int(len(image_filenames) * split_ratios[1])

    # Split the filenames into three sets
    train_filenames = image_filenames[:num_train]
    val_filenames = image_filenames[num_train:num_train+num_val]
    test_filenames = image_filenames[num_train+num_val:]

    # Create the main target directory if it doesn't exist
    os.makedirs(target_dir, exist_ok=True)

    for set_name, filenames in zip(['train', 'val', 'test'], [train_filenames, val_filenames, test_filenames]):
        set_dir = os.path.join(target_dir, set_name)
        os.makedirs(set_dir, exist_ok=True)

        image_dir = os.path.join(set_dir, 'images')
        label_dir = os.path.join(set_dir, 'labels')
        os.makedirs(image_dir, exist_ok=True)
        os.makedirs(label_dir, exist_ok=True)

        for filename in filenames:
            image_path = os.path.join(source_dir, 'image', filename)
            label_path = os.path.join(source_dir, 'label', filename[:-4] + '.txt')
            target_image_path = os.path.join(image_dir, filename)
            target_label_path = os.path.join(label_dir, filename[:-4] + '.txt')

            shutil.copy(image_path, target_image_path)
            shutil.copy(label_path, target_label_path)

# Example usage:
source_dir = '/content/tmp'  # Replace with your source directory
target_dir = '/content/dataset'  # Replace with your target directory
split_ratios = (0.8, 0.1, 0.1)  # 70% training, 20% validation, 10% testing

split_dataset(source_dir, target_dir, split_ratios)

print(len(os.listdir('/content/dataset/train/images')))
print(len(os.listdir('/content/dataset/test/images')))
print(len(os.listdir('/content/dataset/val/images')))
print(len(os.listdir('/content/dataset/train/labels')))
print(len(os.listdir('/content/dataset/test/labels')))
print(len(os.listdir('/content/dataset/val/labels')))

import os
from PIL import Image

def normalize_labels(image_dir, label_dir):
  for filename in os.listdir(image_dir):
    if filename.endswith(('.jpg', '.png', '.jpeg')):
      image_path = os.path.join(image_dir, filename)
      label_path = os.path.join(label_dir, filename[:-4] + '.txt')

      with Image.open(image_path) as img:
        img_width, img_height = img.size

      with open(label_path, 'r') as f:
        lines = f.readlines()

      with open(label_path, 'w') as f:
        for line in lines:
          parts = line.strip().split()
          class_id, x1, y1, width, height = map(float, parts)

          # Clip coordinates to image boundaries
          x1 = x1+width/2
          y1 = y1+height/2

          normalized_x1 = x1 / img_width
          normalized_y1 = y1 / img_height
          width = width / img_width
          height = height / img_height

          # Check for valid width and height (optional)
          if width > 0 and height > 0:
            normalized_line = f"{class_id} {normalized_x1:.6f} {normalized_y1:.6f} {width:.6f} {height:.6f}\n"
            f.write(normalized_line)

# Example usage:
image_dir = '/content/dataset/train/images/'
label_dir = '/content/dataset/train/labels/'
normalize_labels(image_dir, label_dir)

# Example usage:
image_dir = '/content/dataset/val/images/'
label_dir = '/content/dataset/val/labels/'
normalize_labels(image_dir, label_dir)

# Example usage:
image_dir = '/content/dataset/test/images/'
label_dir = '/content/dataset/test/labels/'
normalize_labels(image_dir, label_dir)

!pip install ultralytics

import torch
# Load the YOLOv8 model using the ultralytics library
from ultralytics import YOLO

# Specify the path to your downloaded model file
model_path = "/content/yolov8n.pt"

# Load the model
model = YOLO(model_path)

print("YOLOv8n model loaded successfully!")

import os

def create_data_yaml(data_dir, nc, names):
    yaml_content = f"""
# Dataset information
path: {os.path.join(data_dir)}
train: {os.path.join('train', 'images')}
val: {os.path.join('val', 'images')}
test: {os.path.join('test', 'images')}

# Classes
nc: {nc}
names:
  0: {names[0]}
"""

    with open('data.yaml', 'w') as f:
        f.write(yaml_content)

data_dir = '/content/dataset'
num_classes = 1  # Adjust this to your actual number of classes
names = ['UAV']  # Replace with your class names

create_data_yaml(data_dir, num_classes, names)

model.info()

# Print the model summary
print(model)

# Train the model with data augmentation
results = model.train(model='/content/yolov8n.pt',  # Start from a pre-trained model
                     data='/content/data.yaml',  # Path to your dataset YAML file
                     epochs=1,                # Number of epochs
                     batch=32,                 # Batch size
                     imgsz=640 )

model.info()

# prompt: I need to test my trained model on test dataset mentioned above - I need image vizualization with bordering boxes and also other matrics

import matplotlib.pyplot as plt
import cv2

best_model = YOLO(results) if isinstance(results, str) else model

# Define the path to your test images directory
test_images_dir = "/content/dataset/test/images"

# Loop through each image in the test directory
for image_file in os.listdir(test_images_dir):
    image_path = os.path.join(test_images_dir, image_file)

    # Perform inference
    results = best_model.predict(source=image_path, save=False, conf=0.25)

    # Visualize results
    result = results[0]
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for display

    for box in result.boxes:
        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())  # Convert tensor to list
        conf = box.conf.item()  # Get the confidence score
        cls = box.cls.item()     # Get the class ID
        class_name = names[int(cls)]  # Map the class ID to its name

        # Draw bounding box
        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(image, f"{class_name} {conf:.2f}", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

    plt.figure(figsize=(10, 10))
    plt.imshow(image)
    plt.axis('off')
    plt.title(f"Prediction for {image_file}")
    plt.show()

# Evaluate the model on the test set and get metrics
metrics = best_model.val(data="/content/data.yaml")